{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from csi_camera import CSI_Camera\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_fps = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple draw label on an image; in our case, the video frame\n",
    "def draw_label(cv_image, label_text, label_position):\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.5\n",
    "    color = (255,255,255)\n",
    "    # You can get the size of the string with cv2.getTextSize here\n",
    "    cv2.putText(cv_image, label_text, label_position, font_face, scale, color, 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a frame from the camera, and draw the FPS on the image if desired\n",
    "# Return an image\n",
    "def read_camera(csi_camera, display_fps):\n",
    "    _ , camera_image=csi_camera.read()\n",
    "    if display_fps:\n",
    "        draw_label(camera_image, \"Frames Displayed (PS): \"+str(csi_camera.last_frames_displayed),(10,20))\n",
    "        draw_label(camera_image, \"Frames Read (PS): \"+str(csi_camera.last_frames_read),(10,40))\n",
    "    return camera_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def show_array_IPython():\n",
    "    display_id = None\n",
    "    def wrapper(array: np.ndarray, fmt='jpeg'):\n",
    "        nonlocal display_id\n",
    "        f = BytesIO()\n",
    "        PIL.Image.fromarray(array).save(f, fmt)\n",
    "        obj = IPython.display.Image(data=f.getvalue())\n",
    "        if display_id is not None:\n",
    "            IPython.display.update_display(obj, display_id=display_id)\n",
    "        else:\n",
    "            display_id = IPython.display.display(obj, display_id=True).display_id\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def outter():\n",
    "#     id = None\n",
    "#     def inner(new_id = None):\n",
    "#         nonlocal id\n",
    "#         if new_id is not None:\n",
    "#             id = new_id\n",
    "#         return id\n",
    "#     return inner\n",
    "# o1 = outter()\n",
    "# o2 = outter()\n",
    "# o1(\"aaaa\")\n",
    "# o1()\n",
    "# o2()\n",
    "# o2(\"bbbbb\")\n",
    "# o2()\n",
    "# o1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good for 1280x720\n",
    "DISPLAY_WIDTH=640\n",
    "DISPLAY_HEIGHT=360\n",
    "# For 1920x1080\n",
    "# DISPLAY_WIDTH=960\n",
    "# DISPLAY_HEIGHT=540\n",
    "\n",
    "# 1920x1080, 30 fps\n",
    "SENSOR_MODE_1080=2\n",
    "# 1280x720, 60 fps\n",
    "SENSOR_MODE_720=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detect():\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        \"/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "    )\n",
    "    eye_cascade = cv2.CascadeClassifier(\n",
    "        \"/usr/share/opencv4/haarcascades/haarcascade_eye.xml\"\n",
    "    )\n",
    "    left_camera = CSI_Camera()\n",
    "    left_camera.create_gstreamer_pipeline(\n",
    "            sensor_id=0,\n",
    "            sensor_mode=SENSOR_MODE_720,\n",
    "            framerate=60,\n",
    "            flip_method=2,\n",
    "            display_height=DISPLAY_HEIGHT,\n",
    "            display_width=DISPLAY_WIDTH,\n",
    "    )\n",
    "    left_camera.open(left_camera.gstreamer_pipeline)\n",
    "    left_camera.start()\n",
    "\n",
    "    if (\n",
    "        not left_camera.video_capture.isOpened()\n",
    "     ):\n",
    "        # Cameras did not open, or no camera attached\n",
    "\n",
    "        print(\"Unable to open any cameras\")\n",
    "        # TODO: Proper Cleanup\n",
    "        SystemExit(0)\n",
    "    try:\n",
    "        # Start counting the number of frames read and displayed\n",
    "        left_camera.start_counting_fps()\n",
    "        show = show_array_IPython()\n",
    "        while True:\n",
    "            img = read_camera(left_camera,False)\n",
    "            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #--- Start Face Detection ---#\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                roi_gray = gray[y : y + h, x : x + w]\n",
    "                roi_color = img[y : y + h, x : x + w]\n",
    "                eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "                for (ex, ey, ew, eh) in eyes:\n",
    "                    cv2.rectangle(\n",
    "                        roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2\n",
    "                    )\n",
    "            #--- End Face Detection ---#\n",
    "            \n",
    "            if show_fps:\n",
    "                draw_label(img, \"Frames Displayed (PS): \"+str(left_camera.last_frames_displayed),(10,20))\n",
    "                draw_label(img, \"Frames Read (PS): \"+str(left_camera.last_frames_read),(10,40))\n",
    "            # cv2.imshow(\"Face Detect\", img)\n",
    "            show(img)\n",
    "            left_camera.frames_displayed += 1\n",
    "    except KeyboardInterrupt as e:\n",
    "        print(f\"KeyboardInterrupt\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "    finally:\n",
    "        left_camera.stop()\n",
    "        left_camera.release()\n",
    "        print(\"Released Video Resource\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
